# -*- coding: utf-8 -*-
"""GTZAN_model_test_version_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16MiERwgj8lj2zvyFw5ayszakLPdYKxPN
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
import os
import sys

drive.mount('/content/drive')

# %cd /content/drive/MyDrive
!mkdir -p ModelTesting
# %cd ModelTesting

# Install required libraries
!pip install transformers torch datasets librosa

import torch
from transformers import pipeline, AutoFeatureExtractor, AutoModelForAudioClassification

model_name = "dima806/music_genres_classification"
pipe = pipeline("audio-classification", model=model_name)

feature_extractor = AutoFeatureExtractor.from_pretrained(model_name)
model = AutoModelForAudioClassification.from_pretrained(model_name)

!git clone https://github.com/MTG/mtg-jamendo-dataset

# %cd /content/drive/MyDrive/ModelTesting
!ls
# %cd mtg-jamendo-dataset/scripts

# Add the current directory to the Python path to allow importing local modules
sys.path.insert(0, os.getcwd())

# Install required libraries
!pip install transformers torch datasets librosa
import commons

input_file = '/content/drive/MyDrive/ModelTesting/mtg-jamendo-dataset/data/autotagging.tsv'
tracks, tags, extra = commons.read_file(input_file)

print("Total tracks:", len(tracks))
print("Example track:", list(tracks.items())[0])

genres = ["blues", "classical", "country", "disco", "hiphop", "jazz", "metal", "pop", "reggae", "rock"]

relevant_tracks = {}

for track_id, track_data in tracks.items():
    for genre in track_data["genre"]:
        if genre in genres:
          track_data["track_id"] = track_id
          file_name = track_data["path"]
          relevant_tracks[file_name] = track_data

print("Number of relevant tracks:", len(relevant_tracks))

import os

genres = ["blues", "classical", "country", "disco", "hiphop", "jazz", "metal", "pop", "reggae", "rock"]

relevant_tracks = {}
data_dir = '/content/drive/MyDrive/ModelTesting/audio'  # adjust if needed

for track_id, track_data in tracks.items():
    keep = False
    for genre in track_data["genre"]:
        if genre in genres:
            keep = True
            track_data["track_id"] = track_id
            file_name = track_data["path"]
            relevant_tracks[file_name] = track_data
            break  # no need to check other genres

    if not keep:
        # Delete irrelevant file
        file_path = os.path.join(data_dir, track_data["path"])
        if os.path.exists(file_path):
            os.remove(file_path)

print("Number of relevant tracks:", len(relevant_tracks))

#!mkdir -p content/mtg-jamendo-moodtheme
#!python3 scripts/download/download.py --dataset autotagging_moodtheme --type audio_low content/mtg-jamendo-moodtheme --unpack --remove

def normalize(genre):
    return genre.lower().replace("-", "").replace(" ", "")

genres = [normalize(g) for g in ["blues", "classical", "country", "disco", "hiphop", "jazz", "metal", "pop", "reggae", "rock"]]

import os

base_dir = '/content/drive/MyDrive/ModelTesting/audio'

audio_files = []

for folder in os.listdir(base_dir):
    folder_path = os.path.join(base_dir, folder)
    if os.path.isdir(folder_path):
        # add all audio files from this folder
        audio_files.extend([os.path.join(folder, f)
                            for f in os.listdir(folder_path)
                            if f.endswith((".wav", ".mp3", ".flac"))])

print("Total number of audio files:", len(audio_files))

import os
from tqdm import tqdm

audio_file_path = "/content/drive/MyDrive/ModelTesting/audio"
output_txt = "/content/drive/MyDrive/ModelTesting/final_results.txt"

# Define normalize again (in case itâ€™s not loaded)
def normalize(genre):
    return genre.lower().replace("-", "").replace(" ", "")

# Define target genres
genres = [normalize(g) for g in [
    "blues", "classical", "country", "disco", "hiphop",
    "jazz", "metal", "pop", "reggae", "rock"
]]

# open file in append mode, so if it crashes mid-way, existing data stays
with open(output_txt, "a", encoding="utf-8") as f:
    f.write("TRACK|TRUE GENRES|PREDICTION")

    # loop over relevant_tracks only
    for rel_path, data in tqdm(relevant_tracks.items(), desc="Running predictions"):
        if "predictions" in data:
            print("here")
            continue  # skip already predicted

        # get full path from relative one
        parts = rel_path.split("/")
        if len(parts) < 2:
            continue
        folder, filename = parts[0], parts[1]
        full_path = os.path.join(audio_file_path, folder, filename)

        # skip missing files
        if not os.path.exists(full_path):
            continue

        try:
            preds = pipe(full_path)
            top_pred = normalize(preds[0]["label"])
            data["predictions"] = top_pred  # update dict in case you want it later
        except Exception as e:
            top_pred = "error"
            print("âš ï¸ Error on", rel_path, ":", e)

        # get true genres
        true_genres = [normalize(g) for g in data.get("genre", []) if normalize(g) in genres]

        # write immediately to file (so progress survives)
        f.write(f"{rel_path}|{', '.join(true_genres)}|{top_pred}\n")
        f.flush()  # ðŸ’¾ ensure write is saved immediately

print(f"\nâœ… All results (so far) saved live to: {output_txt}")

"""# Task
Improve the audio classification pipeline by configuring device compatibility (GPU/CPU) in cell `XJZqwP5UNc-r`, loading existing results from `final_results.txt` to skip reprocessing, and implementing batch processing for parallel inference in cell `j6YuHmnNHA__`, ensuring the header is only written once to `final_results.txt`.

## Configure Audio Pipeline for Device Compatibility

### Subtask:
Modify the `pipeline` initialization in cell `XJZqwP5UNc-r` to ensure it uses the appropriate device (GPU if available, otherwise CPU) to prevent CUDA errors. This involves passing a `device` argument to the `pipeline` function, typically `0` for GPU or `-1` for CPU.

**Reasoning**:
The subtask requires modifying the pipeline initialization in cell `XJZqwP5UNc-r` to use the appropriate device (GPU or CPU). I need to add logic to check for CUDA availability and then pass the determined device to the pipeline constructor. This command will provide the complete, modified code for cell `XJZqwP5UNc-r`.
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
import os
import sys

drive.mount('/content/drive')

# %cd /content/drive/MyDrive
!mkdir -p ModelTesting
# %cd ModelTesting

# Install required libraries
!pip install transformers torch datasets librosa

import torch
from transformers import pipeline, AutoFeatureExtractor, AutoModelForAudioClassification

# Determine the device to use (GPU if available, otherwise CPU)
device = 0 if torch.cuda.is_available() else -1
print(f"Using device: {'cuda' if device == 0 else 'cpu'}")

model_name = "dima806/music_genres_classification"
pipe = pipeline("audio-classification", model=model_name, device=device)

feature_extractor = AutoFeatureExtractor.from_pretrained(model_name)
model = AutoModelForAudioClassification.from_pretrained(model_name)

!git clone https://github.com/MTG/mtg-jamendo-dataset

# %cd /content/drive/MyDrive/ModelTesting
!ls
# %cd mtg-jamendo-dataset/scripts

# Add the current directory to the Python path to allow importing local modules
sys.path.insert(0, os.getcwd())

# Install required libraries
!pip install transformers torch datasets librosa
import commons

input_file = '/content/drive/MyDrive/ModelTesting/mtg-jamendo-dataset/data/autotagging.tsv'
tracks, tags, extra = commons.read_file(input_file)

print("Total tracks:", len(tracks))
print("Example track:", list(tracks.items())[0])

"""**Reasoning**:
To avoid reprocessing already analyzed audio files, I need to load the existing predictions from `final_results.txt`. This involves reading the file, parsing each line to extract the relative path, and storing these paths in a set. This set will then be used to skip already processed files in the main prediction loop in cell `j6YuHmnNHA__`.


"""

import os

output_txt = "/content/drive/MyDrive/ModelTesting/final_results.txt"
processed_tracks = set()

# Check if the file exists and has content
if os.path.exists(output_txt) and os.path.getsize(output_txt) > 0:
    with open(output_txt, "r", encoding="utf-8") as f:
        header = f.readline().strip()
        if header == "TRACK|TRUE GENRES|PREDICTION":
            for line in f:
                parts = line.strip().split('|')
                if len(parts) > 0:
                    processed_tracks.add(parts[0])
    print(f"Loaded {len(processed_tracks)} already processed tracks from {output_txt}")
else:
    print(f"No existing results found in {output_txt}. Starting fresh.")

# Initialize already_written to True if the file exists and has a header, else False
already_written = os.path.exists(output_txt) and os.path.getsize(output_txt) > 0 and header == "TRACK|TRUE GENRES|PREDICTION"

"""**Reasoning**:
To implement batch processing and skip already processed files, I need to modify the prediction loop in cell `j6YuHmnNHA__`. This involves collecting file paths into batches, using the `processed_tracks` set to filter out already processed items, and ensuring the header is written only if `already_written` is `False`.


"""

import os
from tqdm import tqdm

audio_file_path = "/content/drive/MyDrive/ModelTesting/audio"
output_txt = "/content/drive/MyDrive/ModelTesting/final_results.txt"

# Define normalize again (in case itâ€™s not loaded)
def normalize(genre):
    return genre.lower().replace("-", "").replace(" ", "")

# Define target genres
genres = [normalize(g) for g in [
    "blues", "classical", "country", "disco", "hiphop",
    "jazz", "metal", "pop", "reggae", "rock"
]]

# Load processed tracks and already_written flag (if not already loaded)
if 'processed_tracks' not in locals():
    processed_tracks = set()
    already_written = False
    if os.path.exists(output_txt) and os.path.getsize(output_txt) > 0:
        with open(output_txt, "r", encoding="utf-8") as f:
            header_line = f.readline().strip()
            if header_line == "TRACK|TRUE GENRES|PREDICTION":
                already_written = True
                for line in f:
                    parts = line.strip().split('|')
                    if len(parts) > 0:
                        processed_tracks.add(parts[0])

# Open file in append mode. Write header only if not already written.
with open(output_txt, "a", encoding="utf-8") as f:
    if not already_written:
        f.write("TRACK|TRUE GENRES|PREDICTION\n") # Add newline character
        f.flush() # Ensure header is written immediately

    batch_size = 16  # You can adjust this based on your GPU memory and file sizes
    current_batch_files = []
    current_batch_data = []

    # Filter out already processed tracks
    tracks_to_process = {}
    for rel_path, data in relevant_tracks.items():
        if rel_path not in processed_tracks:
            tracks_to_process[rel_path] = data

    for rel_path, data in tqdm(tracks_to_process.items(), desc="Running predictions", total=len(tracks_to_process)):
        # get full path from relative one
        parts = rel_path.split("/")
        if len(parts) < 2:
            continue
        folder, filename = parts[0], parts[1]
        full_path = os.path.join(audio_file_path, folder, filename)

        # skip missing files
        if not os.path.exists(full_path):
            continue

        current_batch_files.append(full_path)
        current_batch_data.append((rel_path, data))

        if len(current_batch_files) == batch_size:
            try:
                batch_preds = pipe(current_batch_files)
                for i, (path, track_data) in enumerate(current_batch_data):
                    top_pred = normalize(batch_preds[i][0]["label"])
                    track_data["predictions"] = top_pred

                    # get true genres
                    true_genres = [normalize(g) for g in track_data.get("genre", []) if normalize(g) in genres]

                    # write immediately to file
                    f.write(f"{path}|{', '.join(true_genres)}|{top_pred}\n") # Add newline character
                f.flush() # Ensure batch is written immediately
            except Exception as e:
                for path, track_data in current_batch_data:
                    print("âš ï¸ Error on", path, ":", e)
                    # Write error for each track in the batch
                    true_genres = [normalize(g) for g in track_data.get("genre", []) if normalize(g) in genres]
                    f.write(f"{path}|{', '.join(true_genres)}|error\n") # Add newline character
                f.flush() # Ensure error batch is written immediately

            current_batch_files = []
            current_batch_data = []

    # Process any remaining files in the last batch
    if current_batch_files:
        try:
            batch_preds = pipe(current_batch_files)
            for i, (path, track_data) in enumerate(current_batch_data):
                top_pred = normalize(batch_preds[i][0]["label"])
                track_data["predictions"] = top_pred

                # get true genres
                true_genres = [normalize(g) for g in track_data.get("genre", []) if normalize(g) in genres]

                # write immediately to file
                f.write(f"{path}|{', '.join(true_genres)}|{top_pred}\n") # Add newline character
            f.flush() # Ensure batch is written immediately
        except Exception as e:
            for path, track_data in current_batch_data:
                print("âš ï¸ Error on", path, ":", e)
                # Write error for each track in the batch
                true_genres = [normalize(g) for g in track_data.get("genre", []) if normalize(g) in genres]
                f.write(f"{path}|{', '.join(true_genres)}|error\n") # Add newline character
            f.flush() # Ensure error batch is written immediately

print(f"\nâœ… All results (so far) saved live to: {output_txt}")

"""**Reasoning**:
The previous code failed because `relevant_tracks` was not defined. This variable is crucial for the prediction loop and is generated from the `tracks` dictionary. I will add logic to ensure `relevant_tracks` is initialized from `tracks` at the beginning of the cell if it's not already present in the global scope, using the `normalize` function and `genres` list defined within the cell.


"""

import os
from tqdm import tqdm

audio_file_path = "/content/drive/MyDrive/ModelTesting/audio"
output_txt = "/content/drive/MyDrive/ModelTesting/final_results.txt"

# Define normalize again (in case itâ€™s not loaded)
def normalize(genre):
    return genre.lower().replace("-", "").replace(" ", "")

# Define target genres
genres = [normalize(g) for g in [
    "blues", "classical", "country", "disco", "hiphop",
    "jazz", "metal", "pop", "reggae", "rock"
]]

# Ensure 'relevant_tracks' is defined if it was not propagated from previous cells
if 'relevant_tracks' not in globals():
    print("Initializing 'relevant_tracks' as it was not found in global scope.")
    relevant_tracks = {}
    # Assuming 'tracks' is available globally from previous cells (XJZqwP5UNc-r)
    if 'tracks' in globals():
        for track_id, track_data in tracks.items():
            # Check each genre in the track's genre set
            for original_genre in track_data.get("genre", []):
                if normalize(original_genre) in genres:
                    # Create a copy to avoid modifying the original 'tracks' entry
                    data_copy = track_data.copy()
                    data_copy["track_id"] = track_id
                    file_name = data_copy["path"]
                    relevant_tracks[file_name] = data_copy
                    break  # Found a relevant genre, move to next track
    else:
        print("Error: 'tracks' variable not found. Cannot initialize 'relevant_tracks'. Proceeding with an empty dictionary.")
        relevant_tracks = {}

# Load processed tracks and already_written flag (if not already loaded)
# This block ensures 'processed_tracks' and 'already_written' are properly initialized
# even if the previous cell defining them was skipped or if kernel restarted.
if 'processed_tracks' not in locals():
    processed_tracks = set()
    already_written = False
    if os.path.exists(output_txt) and os.path.getsize(output_txt) > 0:
        with open(output_txt, "r", encoding="utf-8") as f:
            header_line = f.readline().strip()
            if header_line == "TRACK|TRUE GENRES|PREDICTION":
                already_written = True
                for line in f:
                    parts = line.strip().split('|')
                    if len(parts) > 0:
                        processed_tracks.add(parts[0])


# Open file in append mode. Write header only if not already written.
with open(output_txt, "a", encoding="utf-8") as f:
    if not already_written:
        f.write("TRACK|TRUE GENRES|PREDICTION\n") # Add newline character
        f.flush() # Ensure header is written immediately

    batch_size = 16  # You can adjust this based on your GPU memory and file sizes
    current_batch_files = []
    current_batch_data = []

    # Filter out already processed tracks
    tracks_to_process = {}
    for rel_path, data in relevant_tracks.items():
        if rel_path not in processed_tracks:
            tracks_to_process[rel_path] = data

    for rel_path, data in tqdm(tracks_to_process.items(), desc="Running predictions", total=len(tracks_to_process)):
        # get full path from relative one
        parts = rel_path.split("/")
        if len(parts) < 2:
            continue
        folder, filename = parts[0], parts[1]
        full_path = os.path.join(audio_file_path, folder, filename)

        # skip missing files
        if not os.path.exists(full_path):
            continue

        current_batch_files.append(full_path)
        current_batch_data.append((rel_path, data))

        if len(current_batch_files) == batch_size:
            try:
                batch_preds = pipe(current_batch_files)
                for i, (path, track_data) in enumerate(current_batch_data):
                    top_pred = normalize(batch_preds[i][0]["label"])
                    track_data["predictions"] = top_pred

                    # get true genres
                    true_genres = [normalize(g) for g in track_data.get("genre", []) if normalize(g) in genres]

                    # write immediately to file
                    f.write(f"{path}|{', '.join(true_genres)}|{top_pred}\n") # Add newline character
                f.flush() # Ensure batch is written immediately
            except Exception as e:
                for path, track_data in current_batch_data:
                    print("âš ï¸ Error on", path, ":", e)
                    # Write error for each track in the batch
                    true_genres = [normalize(g) for g in track_data.get("genre", []) if normalize(g) in genres]
                    f.write(f"{path}|{', '.join(true_genres)}|error\n") # Add newline character
                f.flush() # Ensure error batch is written immediately

            current_batch_files = []
            current_batch_data = []

    # Process any remaining files in the last batch
    if current_batch_files:
        try:
            batch_preds = pipe(current_batch_files)
            for i, (path, track_data) in enumerate(current_batch_data):
                top_pred = normalize(batch_preds[i][0]["label"])
                track_data["predictions"] = top_pred

                # get true genres
                true_genres = [normalize(g) for g in track_data.get("genre", []) if normalize(g) in genres]

                # write immediately to file
                f.write(f"{path}|{', '.join(true_genres)}|{top_pred}\n") # Add newline character
            f.flush() # Ensure batch is written immediately
        except Exception as e:
            for path, track_data in current_batch_data:
                print("âš ï¸ Error on", path, ":", e)
                # Write error for each track in the batch
                true_genres = [normalize(g) for g in track_data.get("genre", []) if normalize(g) in genres]
                f.write(f"{path}|{', '.join(true_genres)}|error\n") # Add newline character
            f.flush() # Ensure error batch is written immediately

print(f"\nâœ… All results (so far) saved live to: {output_txt}")

"""# Task
Reduce the batch size in cell `8cd1776c` to 1, and ensure the audio classification pipeline processes files without encountering CUDA memory errors.

## Reduce Batch Size and Update Batch Processing

### Subtask:
Modify the batch processing loop in cell `8cd1776c` to significantly reduce the `batch_size` to mitigate the 'CUDA out of memory' error. The previous batch size of 16 was too large for the available GPU memory. A smaller batch size will be implemented to prevent this issue.

**Reasoning**:
The subtask requires modifying the `batch_size` in cell `8cd1776c` to `1` to mitigate CUDA out of memory errors. I will replace the existing code in cell `8cd1776c` with the updated version that has `batch_size = 1`.
"""

import os
from tqdm import tqdm

audio_file_path = "/content/drive/MyDrive/ModelTesting/audio"
output_txt = "/content/drive/MyDrive/ModelTesting/final_results.txt"

# Define normalize again (in case itâ€™s not loaded)
def normalize(genre):
    return genre.lower().replace("-", "").replace(" ", "")

# Define target genres
genres = [normalize(g) for g in [
    "blues", "classical", "country", "disco", "hiphop",
    "jazz", "metal", "pop", "reggae", "rock"
]]

# Ensure 'relevant_tracks' is defined if it was not propagated from previous cells
if 'relevant_tracks' not in globals():
    print("Initializing 'relevant_tracks' as it was not found in global scope.")
    relevant_tracks = {}
    # Assuming 'tracks' is available globally from previous cells (XJZqwP5UNc-r)
    if 'tracks' in globals():
        for track_id, track_data in tracks.items():
            # Check each genre in the track's genre set
            for original_genre in track_data.get("genre", []):
                if normalize(original_genre) in genres:
                    # Create a copy to avoid modifying the original 'tracks' entry
                    data_copy = track_data.copy()
                    data_copy["track_id"] = track_id
                    file_name = data_copy["path"]
                    relevant_tracks[file_name] = data_copy
                    break  # Found a relevant genre, move to next track
    else:
        print("Error: 'tracks' variable not found. Cannot initialize 'relevant_tracks'. Proceeding with an empty dictionary.")
        relevant_tracks = {}

# Load processed tracks and already_written flag (if not already loaded)
# This block ensures 'processed_tracks' and 'already_written' are properly initialized
# even if the previous cell defining them was skipped or if kernel restarted.
if 'processed_tracks' not in locals():
    processed_tracks = set()
    already_written = False
    if os.path.exists(output_txt) and os.path.getsize(output_txt) > 0:
        with open(output_txt, "r", encoding="utf-8") as f:
            header_line = f.readline().strip()
            if header_line == "TRACK|TRUE GENRES|PREDICTION":
                already_written = True
                for line in f:
                    parts = line.strip().split('|')
                    if len(parts) > 0:
                        processed_tracks.add(parts[0])


# Open file in append mode. Write header only if not already written.
with open(output_txt, "a", encoding="utf-8") as f:
    if not already_written:
        f.write("TRACK|TRUE GENRES|PREDICTION\n") # Add newline character
        f.flush() # Ensure header is written immediately

    batch_size = 1  # Adjusted batch size to 1
    current_batch_files = []
    current_batch_data = []

    # Filter out already processed tracks
    tracks_to_process = {}
    for rel_path, data in relevant_tracks.items():
        if rel_path not in processed_tracks:
            tracks_to_process[rel_path] = data

    for rel_path, data in tqdm(tracks_to_process.items(), desc="Running predictions", total=len(tracks_to_process)):
        # get full path from relative one
        parts = rel_path.split("/")
        if len(parts) < 2:
            continue
        folder, filename = parts[0], parts[1]
        full_path = os.path.join(audio_file_path, folder, filename)

        # skip missing files
        if not os.path.exists(full_path):
            continue

        current_batch_files.append(full_path)
        current_batch_data.append((rel_path, data))

        if len(current_batch_files) == batch_size:
            try:
                batch_preds = pipe(current_batch_files)
                for i, (path, track_data) in enumerate(current_batch_data):
                    top_pred = normalize(batch_preds[i][0]["label"])
                    track_data["predictions"] = top_pred

                    # get true genres
                    true_genres = [normalize(g) for g in track_data.get("genre", []) if normalize(g) in genres]

                    # write immediately to file
                    f.write(f"{path}|{', '.join(true_genres)}|{top_pred}\n") # Add newline character
                f.flush() # Ensure batch is written immediately
            except Exception as e:
                for path, track_data in current_batch_data:
                    print("âš ï¸ Error on", path, ":", e)
                    # Write error for each track in the batch
                    true_genres = [normalize(g) for g in track_data.get("genre", []) if normalize(g) in genres]
                    f.write(f"{path}|{', '.join(true_genres)}|error\n") # Add newline character
                f.flush() # Ensure error batch is written immediately

            current_batch_files = []
            current_batch_data = []

    # Process any remaining files in the last batch
    if current_batch_files:
        try:
            batch_preds = pipe(current_batch_files)
            for i, (path, track_data) in enumerate(current_batch_data):
                top_pred = normalize(batch_preds[i][0]["label"])
                track_data["predictions"] = top_pred

                # get true genres
                true_genres = [normalize(g) for g in track_data.get("genre", []) if normalize(g) in genres]

                # write immediately to file
                f.write(f"{path}|{', '.join(true_genres)}|{top_pred}\n") # Add newline character
            f.flush() # Ensure batch is written immediately
        except Exception as e:
            for path, track_data in current_batch_data:
                print("âš ï¸ Error on", path, ":", e)
                # Write error for each track in the batch
                true_genres = [normalize(g) for g in track_data.get("genre", []) if normalize(g) in genres]
                f.write(f"{path}|{', '.join(true_genres)}|error\n") # Add newline character
            f.flush() # Ensure error batch is written immediately

print(f"\nâœ… All results (so far) saved live to: {output_txt}")

"""# Task
Prepare the audio dataset for inference by creating a `datasets.Dataset` object containing the full paths and relevant metadata of the audio files that still need processing. Integrate this dataset with the `transformers.pipeline` for efficient batch processing of audio classification, ensuring that previously processed tracks (from `final_results.txt`) are skipped and new predictions are appended to the file. Confirm that this new approach resolves CUDA memory errors and enables successful completion of the audio classification task, saving all results to `final_results.txt`.

## Prepare Audio Dataset for Inference

### Subtask:
Create a `datasets.Dataset` object from the audio file paths that still need processing, including full paths and true genres.

**Reasoning**:
I need to initialize a list to store dictionaries, each containing the full audio path and normalized true genres for tracks that still need processing, and then use this list to create a `datasets.Dataset` object.
"""

import os
from datasets import Dataset

# List to store dictionaries for tracks to be processed
tracks_for_dataset = []

# Iterate through relevant_tracks and prepare data for the dataset
for rel_path, data in relevant_tracks.items():
    # Construct full path to the audio file
    parts = rel_path.split("/")
    if len(parts) < 2:
        continue
    folder, filename = parts[0], parts[1]
    full_path = os.path.join(audio_file_path, folder, filename)

    # Check if the file exists and if it hasn't been processed yet
    if os.path.exists(full_path) and rel_path not in processed_tracks:
        # Normalize and join true genres
        true_genres = [normalize(g) for g in data.get("genre", []) if normalize(g) in genres]
        true_genres_str = ", ".join(true_genres)

        tracks_for_dataset.append({"audio": full_path, "true_genres": true_genres_str, "rel_path": rel_path, "track_data": data})

# Create a datasets.Dataset object
inference_dataset = Dataset.from_list(tracks_for_dataset)

# Print the number of items in the dataset
print(f"Number of tracks identified for processing: {len(inference_dataset)}")